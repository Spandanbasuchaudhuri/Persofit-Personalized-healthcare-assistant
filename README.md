# ğŸ¤– Multimodal AI Assistant

A **Streamlit-powered** personal assistant that fuses conversational AI, voice synthesis, health recommendations, reminder scheduling, and on-device OCRâ€”all runnable **offline** via [Ollama](https://ollama.ai).  
Think of it as a local â€œJarvisâ€ that chats, speaks, plans your workouts, reminds you to hydrate, and even reads receipts or PDFs.

---

## ğŸ“‹ Table of Contents
1. [Project Vision](#-project-vision)  
2. [Feature Matrix](#-feature-matrix)  
3. [Architecture](#-architecture)  
4. [Demo Screens](#-demo-screens)  
5. [Quick Start](#-quick-start)  
6. [Configuration](#-configuration)  
7. [Usage Guide](#-usage-guide)  
8. [Extending the Assistant](#-extending-the-assistant)  
9. [Project Layout](#-project-layout)  
10. [Troubleshooting](#-troubleshooting)  
11. [Roadmap](#-roadmap)  
12. [Contributing](#-contributing)  
13. [License & Credits](#-license--credits)

---

## ğŸ¯ Project Vision
> **Goal:** Provide an offline-first template that demonstrates how to braid **LLMs**, **text-to-speech (TTS)**, **OCR**, and **simple scheduling** into a cohesive Streamlit experience.  
> **Audience:** Students and hobbyists exploring AI integration without cloud fees or vendor lock-in.  
> **Philosophy:** *Local-first*, *hack-friendly*, and *model-agnostic*â€”swap any Ollama model with a single line of code.

---

## âœ¨ Feature Matrix

| Module | Capability | Tech Stack | Key File(s) |
|--------|------------|------------|-------------|
| **Chat Interface** | ğŸ”¹ Real-time streaming chat<br>ğŸ”¹ Markdown-aware rendering | Streamlit UI + `ollama.chat()` | `main.py` (UI), `ai_response.py` |
| **Voice Output** | ğŸ”¹ 8 Edge-TTS voices<br>ğŸ”¹ Toggle per-message | Microsoft Edge TTS | `audio_output.py` |
| **Diet Planner** | ğŸ”¹ Balanced macronutrient breakdown<br>ğŸ”¹ Meal-by-meal suggestions | LLM prompt + validation schema | `diet.py` |
| **Workout Planner** | ğŸ”¹ Beginner â†’ pro routines<br>ğŸ”¹ Progressive-overload logic | LLM prompt w/ load table | `exercise.py` |
| **Smart Reminders** | ğŸ”¹ In-browser toast + sound<br>ğŸ”¹ Runs *client-side* every minute | Streamlit JS hack | `reminders.py` |
| **OCR & PDF Parsing** | ğŸ”¹ Image â†’ text via Tesseract<br>ğŸ”¹ PDF page text with PyPDF2 | `pytesseract`, `pypdf2` | `file_processing.py` |

---

## ğŸ— Architecture
```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       user query/params        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  ai_response â”‚
â”‚   front-endâ”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€ Markdown + audio â”€â”€â”€ â”‚   module     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                                             â”‚
       â”‚     image/PDF                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ file_upload â”‚ â”€â”€â–¶ OCR via Tesseract â”€â”€â”€â”€â”€â”€â–¶â”‚file_processingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                                             â–²
       â”‚ reminders                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ reminders   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€ toast/JS â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  browser tab â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

*All heavy liftingâ€”LLM inference and TTSâ€”happens locally; only a lightweight WebSocket serves Streamlit.*

---

## ğŸ–¼ Demo Screens

> *(GIF / screenshots placeholder â€“ drop into `/assets` once recorded)*

---

## ğŸš€ Quick Start

### 1. Clone & Activate Env

```bash
git clone https://github.com/<you>/multimodal-ai-assistant.git
cd multimodal-ai-assistant
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### 2. Install Python deps

```bash
pip install -r requirements.txt
# or minimal:
pip install streamlit ollama edge-tts pytesseract pillow pypdf2
```

### 3. Install System Deps

| OS          | Command                              |
| ----------- | ------------------------------------ |
| **Ubuntu**  | `sudo apt-get install tesseract-ocr` |
| **Windows** | `choco install tesseract`            |
| **macOS**   | `brew install tesseract`             |

### 4. Pull an LLM

```bash
ollama pull llama3:8b           # or tinyllama:1.1b, gemma:2b, etc.
```

### 5. Launch!

```bash
streamlit run main.py
```

> Your browser pops open at `http://localhost:8501`. Enjoy!

---

## âš™ï¸ Configuration

| Setting                 | How to change                                                               | Default           |
| ----------------------- | --------------------------------------------------------------------------- | ----------------- |
| **Model tag**           | `st.session_state["model_name"]` (sidebar) or hard-code in `ai_response.py` | `llama3`          |
| **Max response tokens** | `max_tokens` param in `ollama.chat()`                                       | `512`             |
| **Voice**               | Sidebar dropdown (Edge TTS voice short-names)                               | `en-US-GuyNeural` |
| **Reminder tone**       | Replace `assets/alert.mp3`                                                  | Soft ding         |
| **OCR language**        | `tesseract_cmd` + `lang='eng+hin'`                                          | `eng`             |

Environment variables (optional):

```bash
# .env.example
EDGE_TTS_PROXY=http://proxy:3128
STREAMLIT_SERVER_PORT=8502
```

---

## ğŸ“– Usage Guide

<details>
<summary><strong>Chat</strong></summary>

1. Select **Chat** in sidebar.
2. Pick a model & temperature (slider).
3. Toggle **Speak replies** if you want TTS.
4. Type prompt â†’ hit *Enter*.
5. Responses stream in; audio auto-plays if enabled.

</details>

<details>
<summary><strong>Diet Planner</strong></summary>

1. Switch to **Diet** tab.
2. Enter calories, dietary preference, allergies.
3. Click *Generate*.
4. Copy plan or have it read aloud.

</details>

<details>
<summary><strong>Reminders</strong></summary>

1. Go to **Reminders**.
2. Fill title + time (HH\:MM, 24-h).
3. Add â†’ shows in list.
4. Keep the tab open; toast pops at set minute.

</details>

---

## ğŸ›  Extending the Assistant

| Add-on idea         | Where to start                                                                             |
| ------------------- | ------------------------------------------------------------------------------------------ |
| **Image Chat**      | Wrap images in `ollama.chat(images=[bytes])` (needs multimodal model).                     |
| **Web Search Tool** | Create `modules/tools/web_search.py` with SerpAPI call and inject function-calling prompt. |
| **Persistent DB**   | Swap `st.session_state` for **SQLite** via SQLModel or Supabase.                           |
| **Docker**          | Write a lightweight `Dockerfile` installing Tesseract + Ollama (with GPU if CUDA).         |

---

## ğŸ—‚ Project Layout

```text
multimodal-ai-assistant/
â”œâ”€â”€ main.py                # Streamlit UI & navigation
â”œâ”€â”€ ai_response.py         # LLM chat / streaming logic
â”œâ”€â”€ audio_output.py        # Edge-TTS wrapper
â”œâ”€â”€ diet.py                # Diet plan generator
â”œâ”€â”€ exercise.py            # Workout plan generator
â”œâ”€â”€ reminders.py           # Client-side reminder logic
â”œâ”€â”€ file_processing.py     # OCR + PDF parsing helpers
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ assets/                # alert.mp3, screenshots, GIFs
â””â”€â”€ README.md
```

---

## ğŸ›‘ Troubleshooting

| Symptom                         | Fix                                                              |
| ------------------------------- | ---------------------------------------------------------------- |
| **â€œTesseractNotFoundErrorâ€**    | Confirm `tesseract` on `$PATH`; run `tesseract --version`.       |
| **Edge-TTS fails behind proxy** | Set `EDGE_TTS_PROXY` env var.                                    |
| **LLM replies too slow**        | Use a smaller quantized model (`llama3:8b-q4_K_M`).              |
| **Reminders donâ€™t fire**        | Keep tab focused OR disable browser â€œbackground tab throttlingâ€. |

---

## ğŸ—º Roadmap

* [ ] **Persist reminders** to SQLite
* [ ] **RAG-powered document Q\&A** (embed uploaded PDFs, vector search)
* [ ] **Voice input** (Whisper CPP or Vosk)
* [ ] **Docker Compose** with Ollama GPU and Streamlit

---

## ğŸ¤ Contributing

1. Fork â†’ create feature branch â†’ commit â†’ PR.
2. Follow [Conventional Commits](https://www.conventionalcommits.org/).
3. Run `pre-commit install` to auto-format with **black** + **ruff**.

---

## ğŸ“œ License & Credits

*Code* released under the **MIT License**.
Built with â™¥ using **Streamlit**, **Ollama**, **Edge-TTS**, and **Tesseract**.
Icons by [Phosphor](https://phosphoricons.com/).
Inspired by projects from @a16z-open-source and the Streamlit community.
